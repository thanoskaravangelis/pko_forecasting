{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from functions.naming import rename_columns\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming your data is in a pandas DataFrame named 'df' with a datetime index\n",
    "# and a column named 'monthly_data'\n",
    "# Replace this with your actual data loading process\n",
    "# For simplicity, I'll create a dummy dataset\n",
    "# Load the data\n",
    "df = pd.read_excel(\"/Users/athanasioskaravangelis/Desktop/RSM BAM/Workshop/pko_forecasting/data/PKO_Initial_Dataset.xlsx\")\n",
    "#rename columns\n",
    "df = rename_columns(df)\n",
    "# select only the values after 2010-01-01\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b-%y')\n",
    "df = df[df['date'] > '2009-12-02']\n",
    "\n",
    "# Ensure the date column is the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Specify columns to exclude\n",
    "exclude_columns = [\n",
    "    'pko_total_supply_malaysia', 'indonesia_disaster', 'malaysia_disaster',\n",
    "    'pko_fob_malaysia', 'jet_fuel_us', 'jet_fuel_europe', 'soybean_oil_zlz2',\n",
    "    'tallow_fob_us_gulf', 'bio_ethanol', 'rspo', 'palm_oil_cif_nwe', 'palm_olein_fob_malaysia',\n",
    "    'palm_stearin_cif_rotterdam', 'fatty_alcohol_c12_14_fob_asia', 'fatty_alcohol_c16_18_fob_asia',\n",
    "    'fatty_alcohol_c12_14_fd_nwe', 'jet_fuel_us_usd_mt'\n",
    "]\n",
    "\n",
    "# Filter the dataset to exclude specified columns\n",
    "df_filtered = df.drop(columns=exclude_columns)\n",
    "\n",
    "# Update NUM_FEATURES based on the filtered dataset\n",
    "num_features = df_filtered.shape[1]\n",
    "num_features\n",
    "\n",
    "# fill nas with average values\n",
    "df = df_filtered.fillna(df_filtered.mean())\n",
    "\n",
    "# Normalize the data using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['pko_cif_rotterdam'] = scaler.fit_transform(df[['pko_cif_rotterdam']])\n",
    "\n",
    "# Create sequences for the LSTM model\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        target = data[i + seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Define the sequence length (number of past months to consider)\n",
    "seq_length = 12\n",
    "\n",
    "# Create sequences and targets\n",
    "X, y = create_sequences(df['pko_cif_rotterdam'].values, seq_length)\n",
    "\n",
    "# Reshape the input data for LSTM (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')  # You can experiment with different optimizers and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 191ms/step - loss: 0.1168 - val_loss: 0.0788\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0923 - val_loss: 0.0654\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0716 - val_loss: 0.0538\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0550 - val_loss: 0.0429\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0409 - val_loss: 0.0329\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0289 - val_loss: 0.0257\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.0230 - val_loss: 0.0221\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0228 - val_loss: 0.0213\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0206 - val_loss: 0.0217\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.0192 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.0184 - val_loss: 0.0227\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0178 - val_loss: 0.0216\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 119ms/step - loss: 0.0172 - val_loss: 0.0207\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0165 - val_loss: 0.0207\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0163 - val_loss: 0.0214\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0160 - val_loss: 0.0210\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0156 - val_loss: 0.0204\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0149 - val_loss: 0.0197\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.0144 - val_loss: 0.0198\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.0141 - val_loss: 0.0191\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0139 - val_loss: 0.0187\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.0137 - val_loss: 0.0190\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0134 - val_loss: 0.0184\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0131 - val_loss: 0.0179\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.0130 - val_loss: 0.0177\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0127 - val_loss: 0.0183\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0127 - val_loss: 0.0181\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0124 - val_loss: 0.0172\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0122 - val_loss: 0.0162\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.0119 - val_loss: 0.0166\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0119 - val_loss: 0.0168\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0119 - val_loss: 0.0163\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0116 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0114 - val_loss: 0.0163\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.0117 - val_loss: 0.0167\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.0114 - val_loss: 0.0152\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.0108 - val_loss: 0.0146\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.0107 - val_loss: 0.0148\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0106 - val_loss: 0.0144\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0105 - val_loss: 0.0140\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0228\n",
      "Test Loss: 0.022817624732851982\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "            forecasted_data\n",
      "2023-12-01       979.184814\n",
      "2024-01-01      1008.167603\n",
      "2024-02-01      1028.095825\n",
      "2024-03-01      1041.834473\n",
      "2024-04-01      1051.318970\n",
      "2024-05-01      1057.867798\n",
      "2024-06-01      1062.394287\n",
      "2024-07-01      1065.524536\n",
      "2024-08-01      1067.690063\n",
      "2024-09-01      1069.188599\n",
      "2024-10-01      1070.224121\n",
      "2024-11-01      1070.937744\n"
     ]
    }
   ],
   "source": [
    "# Forecasting - predicting 12 months into the future\n",
    "last_sequence = X_test[-1]\n",
    "forecast = []\n",
    "\n",
    "for i in range(12):\n",
    "    prediction = model.predict(np.reshape(last_sequence, (1, seq_length, 1)))\n",
    "    forecast.append(prediction[0, 0])\n",
    "    last_sequence = np.roll(last_sequence, -1)\n",
    "    last_sequence[:, -1] = prediction[0, 0]  # Corrected line\n",
    "\n",
    "# Inverse transform the forecasted values to get the actual values\n",
    "forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame for the forecasted values\n",
    "forecast_dates = pd.date_range(start=df.index[-1], periods=13, freq='MS')[1:]\n",
    "forecast_df = pd.DataFrame({'forecasted_data': forecast.flatten()}, index=forecast_dates)\n",
    "\n",
    "# Print or visualize the forecasted data\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
