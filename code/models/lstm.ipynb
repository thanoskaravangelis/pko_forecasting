{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import IPython\n",
    "import IPython.display\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from functions.naming import rename_columns\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"/Users/athanasioskaravangelis/Desktop/RSM BAM/Workshop/pko_forecasting/data/PKO_Initial_Dataset.xlsx\")\n",
    "#rename columns\n",
    "df = rename_columns(df)\n",
    "# select only the values after 2010-01-01\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b-%y')\n",
    "df = df[df['date'] > '2009-12-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_EPOCHS = 20\n",
    "INPUT_WINDOW = 12\n",
    "#NUM_FEATURES = 9  # This will be updated based on the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience,mode='min')\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),optimizer=tf.keras.optimizers.legacy.Adam(),metrics=[tf.metrics.MeanSquaredError()])\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,validation_data=window.val,callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 53)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to exclude\n",
    "exclude_columns = [\n",
    "    'pko_total_supply_malaysia', 'indonesia_disaster', 'malaysia_disaster',\n",
    "    'pko_fob_malaysia', 'jet_fuel_us', 'jet_fuel_europe', 'date', 'soybean_oil_zlz2',\n",
    "    'tallow_fob_us_gulf', 'bio_ethanol', 'rspo', 'palm_oil_cif_nwe', 'palm_olein_fob_malaysia',\n",
    "    'palm_stearin_cif_rotterdam', 'fatty_alcohol_c12_14_fob_asia', 'fatty_alcohol_c16_18_fob_asia',\n",
    "    'fatty_alcohol_c12_14_fd_nwe', 'jet_fuel_us_usd_mt'\n",
    "]\n",
    "\n",
    "# Filter the dataset to exclude specified columns\n",
    "df_filtered = df.drop(columns=exclude_columns)\n",
    "\n",
    "# Update NUM_FEATURES based on the filtered dataset\n",
    "num_features = df_filtered.shape[1]\n",
    "num_features\n",
    "\n",
    "# fill nas with average values\n",
    "df_filtered = df_filtered.fillna(df_filtered.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/35/tbpcvh252s9dy7dhvwv499800000gn/T/ipykernel_13135/221947558.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmulti_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mmulti_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/35/tbpcvh252s9dy7dhvwv499800000gn/T/ipykernel_13135/221947558.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUT_STEPS\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOUT_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         ])\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/35/tbpcvh252s9dy7dhvwv499800000gn/T/ipykernel_13135/3454553861.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, window, patience)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1520\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    X = df_filtered\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    train_df = X[0:133]\n",
    "    val_df = X[133:156]\n",
    "    test_df = X[156:166]\n",
    "\n",
    "    n = len(df)\n",
    "\n",
    "    # Normalize the data\n",
    "    train_mean = train_df.mean()\n",
    "    train_std = train_df.std()\n",
    "    train_df = (train_df - train_mean) / train_std\n",
    "    val_df = (val_df - train_mean) / train_std\n",
    "    test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "    class WindowGenerator():\n",
    "            def __init__(self, input_width, label_width, shift,train_df=train_df, val_df=val_df, test_df=test_df,label_columns=None):\n",
    "\n",
    "                self.train_df = train_df\n",
    "                self.val_df = val_df\n",
    "                self.test_df = test_df\n",
    "                self.label_columns = label_columns\n",
    "                if label_columns is not None:\n",
    "                    self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "                self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "                self.input_width = input_width\n",
    "                self.label_width = label_width\n",
    "                self.shift = shift\n",
    "                self.total_window_size = input_width + shift\n",
    "                self.input_slice = slice(0, input_width)\n",
    "                self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "                self.label_start = self.total_window_size - self.label_width\n",
    "                self.labels_slice = slice(self.label_start, None)\n",
    "                self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "            def split_window(self, features):\n",
    "                inputs = features[:, self.input_slice, :]\n",
    "                labels = features[:, self.labels_slice, :]\n",
    "                if self.label_columns is not None:\n",
    "                    labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
    "\n",
    "                inputs.set_shape([None, self.input_width, None])\n",
    "                labels.set_shape([None, self.label_width, None])\n",
    "                return inputs, labels\n",
    "\n",
    "            def plot(self,model=None,train_mean=0,train_std=0,plot_col='pko_fob_malaysia', max_subplots=5):\n",
    "                inputs, labels = self.example\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plot_col_index = self.column_indices[plot_col]\n",
    "                max_n = min(max_subplots, len(inputs))\n",
    "                for n in range(max_n):\n",
    "                    plt.subplot(max_n, 1, n+1)\n",
    "                    inputs_n = inputs[n, :, plot_col_index] * train_std[plot_col_index] + train_mean[plot_col_index]\n",
    "                    plt.plot(self.input_indices,inputs_n,label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "                    if self.label_columns:\n",
    "                        label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "                    else:\n",
    "                        label_col_index = plot_col_index\n",
    "                    if label_col_index is None:\n",
    "                        continue\n",
    "\n",
    "                    labels_n = labels[n, :, label_col_index] * train_std[plot_col_index] + train_mean[plot_col_index]\n",
    "                    plt.scatter(self.label_indices, labels_n,edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "                    if model is not None:\n",
    "                        predictions = model(inputs)\n",
    "                        predictions = predictions[n, :, label_col_index] * train_std[plot_col_index] + train_mean[plot_col_index]\n",
    "                        print('line 102')\n",
    "                        print (label_col_index,plot_col_index)\n",
    "                        plt.scatter(self.label_indices,predictions,marker='X', edgecolors='k', label='Predictions',c='#ff7f0e', s=64)\n",
    "\n",
    "                    if n == 0:\n",
    "                        plt.legend()\n",
    "            \n",
    "                plt.xlabel('Timeslots [month]')\n",
    "\n",
    "            def make_dataset(self, data):\n",
    "                data = np.array(data, dtype=np.float32)\n",
    "                ds = tf.keras.utils.timeseries_dataset_from_array(data=data,targets=None,sequence_length=self.total_window_size,sequence_stride=1,shuffle=True,batch_size=32,)\n",
    "                ds = ds.map(self.split_window)\n",
    "                return ds\n",
    "            \n",
    "            @property\n",
    "            def train(self):\n",
    "                return train_df\n",
    "\n",
    "            @property\n",
    "            def val(self):\n",
    "                return val_df\n",
    "\n",
    "            @property\n",
    "            def test(self):\n",
    "                return self.make_dataset(self.test_df)\n",
    "\n",
    "            @property\n",
    "            def example(self):\n",
    "                result = getattr(self, '_example', None)\n",
    "                if result is None:\n",
    "                    result = next(iter(self.train))\n",
    "                    self._example = result\n",
    "                return result\n",
    "    OUT_STEPS = 12\n",
    "    multi_window = WindowGenerator(input_width=24,label_width=OUT_STEPS,shift=OUT_STEPS, train_df=train_df,val_df=val_df,test_df=test_df)\n",
    "    multi_val_performance = {}\n",
    "    multi_performance = {}\n",
    "\n",
    "    multi_lstm_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "            tf.keras.layers.Dense(OUT_STEPS* num_features,kernel_initializer=tf.initializers.zeros()),\n",
    "            tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "        ])\n",
    "\n",
    "    history = compile_and_fit(multi_lstm_model, multi_window)\n",
    "\n",
    "    IPython.display.clear_output()\n",
    "\n",
    "    multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
    "    multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
    "    multi_window.plot(multi_lstm_model,train_mean,train_std)\n",
    "        \n",
    "    plt.show()\n",
    "    return multi_lstm_model,train_mean,train_std,n\n",
    "\n",
    "multi_lstm_model,train_mean,train_std,n= train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(multi_lstm_model,n):\n",
    "    label_col_index = 7\n",
    "    plot_col_index = 7\n",
    "    predictions = multi_lstm_model\n",
    "    predictions = predictions[n, :, label_col_index] * train_std[plot_col_index] + train_mean[plot_col_index]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_lstm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k \u001b[38;5;241m=\u001b[39m predict(\u001b[43mmulti_lstm_model\u001b[49m,n)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multi_lstm_model' is not defined"
     ]
    }
   ],
   "source": [
    "k = predict(multi_lstm_model,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
